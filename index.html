<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Voice Assistant</title>
    
    <!-- PWA Meta Tags -->
    <meta name="theme-color" content="#4f46e5"/>
    <link rel="manifest" href="manifest.json">
    <link rel="apple-touch-icon" href="https://placehold.co/192x192/4f46e5/ffffff?text=AI">

    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #f3f4f6;
        }
        .assistant-card {
            background-color: white;
            border-radius: 0.75rem;
            box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
            transition: all 0.3s ease-in-out;
        }
        .assistant-card:hover {
            box-shadow: 0 20px 25px -5px rgba(0, 0, 0, 0.1), 0 10px 10px -5px rgba(0, 0, 0, 0.04);
        }
        .btn-primary {
            background-color: #4f46e5;
            color: white;
            font-weight: 600;
            padding: 0.75rem 1.5rem;
            border-radius: 0.5rem;
            border: none;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .btn-primary:hover {
            background-color: #4338ca;
        }
         .btn-primary:disabled {
            background-color: #a5b4fc;
            cursor: not-allowed;
        }
        .loader {
            border: 4px solid #f3f3f3;
            border-top: 4px solid #4f46e5;
            border-radius: 50%;
            width: 24px;
            height: 24px;
            animation: spin 1s linear infinite;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        .dot-flashing {
            position: relative;
            width: 10px;
            height: 10px;
            border-radius: 5px;
            background-color: #4f46e5;
            color: #4f46e5;
            animation: dotFlashing 1s infinite linear alternate;
            animation-delay: .5s;
            display: inline-block;
            margin: 0 4px;
        }
        .dot-flashing::before, .dot-flashing::after {
            content: '';
            display: inline-block;
            position: absolute;
            top: 0;
            width: 10px;
            height: 10px;
            border-radius: 5px;
            background-color: #4f46e5;
            color: #4f46e5;
            animation: dotFlashing 1s infinite alternate;
        }
        .dot-flashing::before {
            left: -15px;
            animation-delay: 0s;
        }
        .dot-flashing::after {
            left: 15px;
            animation-delay: 1s;
        }
        @keyframes dotFlashing {
            0% {
                background-color: #4f46e5;
            }
            50%,
            100% {
                background-color: #c7d2fe;
            }
        }
    </style>
</head>
<body class="flex items-center justify-center min-h-screen p-4">

    <div class="assistant-card w-full max-w-2xl p-6 md:p-8 space-y-6">
        <div>
            <h1 class="text-3xl font-bold text-gray-900 text-center">Jennifer, Your AI Co-Pilot</h1>
            <p class="text-gray-600 text-center mt-2">Start talking to Jennifer. She's ready to listen.</p>
        </div>

        <div class="flex flex-col items-center space-y-4">
            <div id="statusMessage" class="text-center text-red-500 font-medium h-5"></div>
            <button id="recordButton" class="btn-primary flex items-center justify-center w-full md:w-auto">
                <svg id="mic-icon" xmlns="http://www.w3.org/2000/svg" class="h-6 w-6 mr-2" fill="none" viewBox="0 0 24" stroke="currentColor">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3> 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z" />
                </svg>
                <span id="recordButtonText">Start Conversation</span>
            </button>
            <div id="recording-status" class="text-sm text-gray-500 hidden">
                Listening... <div class="dot-flashing"></div>
            </div>
        </div>

        <!-- Conversation Log -->
        <div id="conversation-container" class="space-y-4">
             <h2 class="text-xl font-semibold text-gray-800 border-b pb-2">Conversation</h2>
             <div id="conversation" class="h-48 overflow-y-auto p-4 bg-gray-50 rounded-lg border">
                <p class="text-gray-400">Your conversation will appear here...</p>
            </div>
        </div>

        <!-- AI Assistant Notes -->
         <div id="ai-notes-container" class="space-y-4">
             <h2 class="text-xl font-semibold text-gray-800 border-b pb-2">Jennifer's Follow-up</h2>
             <div id="aiNotes" class="h-32 overflow-y-auto p-4 bg-gray-50 rounded-lg border">
                 <p class="text-gray-400">Jennifer's questions will appear here...</p>
             </div>
             <div id="ai-loading" class="hidden flex items-center justify-center">
                <div class="loader"></div>
                <p class="ml-2 text-gray-600">Assistant is thinking...</p>
             </div>
        </div>


        <!-- To-Do List -->
        <div id="todo-container" class="space-y-4">
            <h2 class="text-xl font-semibold text-gray-800 border-b pb-2">To-Do List</h2>
            <div id="todoList" class="p-4 bg-gray-50 rounded-lg border">
                <p class="text-gray-400">Your to-do list will appear here after the conversation.</p>
            </div>
            <div class="text-center">
                <button id="copyToDoListButton" class="hidden btn-primary mt-2">Copy To-Do List</button>
                <p id="copyStatus" class="text-sm text-green-600 mt-2 h-4"></p>
            </div>
        </div>

    </div>

    <script>
        // PWA Service Worker Registration
        if ('serviceWorker' in navigator) {
            window.addEventListener('load', () => {
                navigator.serviceWorker.register('/sw.js')
                    .then(registration => {
                        console.log('ServiceWorker registration successful with scope: ', registration.scope);
                    })
                    .catch(error => {
                        console.log('ServiceWorker registration failed: ', error);
                    });
            });
        }

        const recordButton = document.getElementById('recordButton');
        const recordButtonText = document.getElementById('recordButtonText');
        const micIcon = document.getElementById('mic-icon');
        const recordingStatus = document.getElementById('recording-status');
        const conversationDiv = document.getElementById('conversation');
        const aiNotesDiv = document.getElementById('aiNotes');
        const todoListDiv = document.getElementById('todoList');
        const aiLoading = document.getElementById('ai-loading');
        const statusMessage = document.getElementById('statusMessage');
        const copyToDoListButton = document.getElementById('copyToDoListButton');
        const copyStatus = document.getElementById('copyStatus');

        let sessionActive = false;
        let recognition;
        let conversationHistory = [];
        let currentSpeech = null; // To hold the current TTS audio object
        
        // Check for browser support
        if ('webkitSpeechRecognition' in window) {
            recognition = new webkitSpeechRecognition();
            recognition.continuous = false; // Important: Process speech after a pause
            recognition.interimResults = false; // We only need the final result
            recognition.lang = 'en-US';

            recognition.onstart = () => {
                recordingStatus.classList.remove('hidden');
            };

            recognition.onend = () => {
                recordingStatus.classList.add('hidden');
            };
            
            recognition.onresult = (event) => {
                if (currentSpeech) {
                    currentSpeech.pause(); 
                }
                
                recognition.stop(); 
                
                const transcript = event.results[event.results.length - 1][0].transcript.trim();

                if (transcript) {
                    if (conversationDiv.querySelector('.text-gray-400')) {
                        conversationDiv.innerHTML = ''; // Clear initial message
                    }
                    const userMessage = document.createElement('p');
                    userMessage.innerHTML = `<span class="font-semibold text-indigo-600">You:</span> ${transcript}`;
                    conversationDiv.appendChild(userMessage);
                    conversationDiv.scrollTop = conversationDiv.scrollHeight;
                    
                    conversationHistory.push({ role: "user", parts: [{ text: transcript }] });

                    // Always treat speech as part of the ongoing conversation
                    getAIAssistance("Respond conversationally, continuing the thread. Keep it brief.", false);

                } else {
                    if (sessionActive) {
                        try { recognition.start(); } catch(e) {}
                    }
                }
            };

            recognition.onerror = (event) => {
                console.error("Speech recognition error:", event.error);
                if (event.error === 'not-allowed') {
                    statusMessage.textContent = 'Microphone access was denied. Please allow it in your browser settings.';
                } else if (event.error !== 'no-speech') {
                     console.log("No speech detected, waiting for user to speak.");
                }
            };
        } else {
            recordButton.disabled = true;
            recordButtonText.textContent = 'Not Supported';
            statusMessage.textContent = 'Speech recognition is not supported in this browser. Please try Chrome.';
        }

        recordButton.addEventListener('click', () => {
            if (sessionActive) {
                // User clicks "End Conversation"
                sessionActive = false;
                if (currentSpeech) {
                    currentSpeech.pause();
                }
                recognition.stop();
                recordButtonText.textContent = 'Start Conversation';
                recordingStatus.classList.add('hidden');

                // Generate/update the to-do list from the full conversation history
                if (conversationHistory.length > 0) {
                    getAIAssistance("Analyze the entire conversation and extract all action items. Format them as a markdown to-do list. The output must *only* contain the list items, starting each with a hyphen.", true);
                }

            } else {
                // User clicks "Start Conversation"
                sessionActive = true;
                recordButtonText.textContent = 'End Conversation';
                
                if (window.AudioContext && window.audioCtx && window.audioCtx.state === 'suspended') {
                    window.audioCtx.resume();
                }

                // If this is the very first time the button is clicked, clear placeholder text.
                // On subsequent starts, the conversation continues from where it left off.
                if (conversationHistory.length === 0) {
                    conversationDiv.innerHTML = '';
                    aiNotesDiv.innerHTML = '';
                    todoListDiv.innerHTML = '<p class="text-gray-400">Your to-do list will appear here after the conversation.</p>';
                    copyToDoListButton.classList.add('hidden');
                    copyStatus.textContent = '';
                }
                recognition.start();
            }
        });

        copyToDoListButton.addEventListener('click', () => {
            const todoItems = Array.from(todoListDiv.querySelectorAll('li'));
            if (todoItems.length === 0) {
                copyStatus.textContent = 'Nothing to copy.';
                setTimeout(() => { copyStatus.textContent = '' }, 3000);
                return;
            }

            // Format the list for plain text pasting
            const textToCopy = todoItems.map(item => `• ${item.textContent}`).join('\n');

            // Use a temporary textarea to perform the copy command
            const textArea = document.createElement('textarea');
            textArea.value = textToCopy;
            document.body.appendChild(textArea);
            textArea.select();
            try {
                document.execCommand('copy');
                copyStatus.textContent = '✅ Copied to clipboard!';
            } catch (err) {
                copyStatus.textContent = '❌ Failed to copy.';
                console.error('Failed to copy text: ', err);
            }
            document.body.removeChild(textArea);

            setTimeout(() => { copyStatus.textContent = '' }, 3000);
        });

        function base64ToArrayBuffer(base64) {
            const binaryString = window.atob(base64);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            return bytes.buffer;
        }

        function pcmToWav(pcmData, sampleRate) {
            const numChannels = 1;
            const bitsPerSample = 16;
            const byteRate = sampleRate * numChannels * bitsPerSample / 8;
            const blockAlign = numChannels * bitsPerSample / 8;
            const dataSize = pcmData.length * 2;
            const buffer = new ArrayBuffer(44 + dataSize);
            const view = new DataView(buffer);
            view.setUint32(0, 0x52494646, false);
            view.setUint32(4, 36 + dataSize, true);
            view.setUint32(8, 0x57415645, false);
            view.setUint32(12, 0x666d7420, false);
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, numChannels, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, byteRate, true);
            view.setUint16(32, blockAlign, true);
            view.setUint16(34, bitsPerSample, true);
            view.setUint32(36, 0x64617461, false);
            view.setUint32(40, dataSize, true);
            for (let i = 0; i < pcmData.length; i++) {
                view.setInt16(44 + i * 2, pcmData[i], true);
            }
            return new Blob([view], { type: 'audio/wav' });
        }

        function markdownListToHtml(text) {
            if (text.includes('<li>')) {
                return text;
            }
            const lines = text.trim().split('\n');
            let html = '<ul class="list-disc list-inside space-y-1 text-gray-700">';
            for (const line of lines) {
                const trimmedLine = line.trim();
                const match = trimmedLine.match(/^[\*\-]\s+(.*)/);
                if (match) {
                    html += `<li>${match[1]}</li>`;
                } else if (trimmedLine) {
                    html += `<li>${trimmedLine}</li>`;
                }
            }
            html += '</ul>';
            return html;
        }

        function getAndPlayTTS(text) {
             return new Promise((resolve, reject) => {
                const cleanedText = text.replace(/[*_`]/g, '');
                const apiKey = "";
                const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key=${apiKey}`;

                const payload = {
                    contents: [{ parts: [{ text: cleanedText }] }],
                    generationConfig: {
                        responseModalities: ["AUDIO"],
                        speechConfig: { voiceConfig: { prebuiltVoiceConfig: { voiceName: "Erinome" } } }
                    },
                    model: "gemini-2.5-flash-preview-tts"
                };
                
                fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                })
                .then(response => {
                    if (!response.ok) throw new Error(`TTS API call failed with status: ${response.status}`);
                    return response.json();
                })
                .then(result => {
                    const part = result?.candidates?.[0]?.content?.parts?.[0];
                    const audioData = part?.inlineData?.data;
                    const mimeType = part?.inlineData?.mimeType;

                    if (audioData && mimeType && mimeType.startsWith("audio/")) {
                        const sampleRateMatch = mimeType.match(/rate=(\d+)/);
                        if (!sampleRateMatch) throw new Error("Sample rate not found in mimeType");
                        
                        const sampleRate = parseInt(sampleRateMatch[1], 10);
                        const pcmData = base64ToArrayBuffer(audioData);
                        const pcm16 = new Int16Array(pcmData);
                        const wavBlob = pcmToWav(pcm16, sampleRate);
                        const audioUrl = URL.createObjectURL(wavBlob);
                        
                        currentSpeech = new Audio(audioUrl);
                        currentSpeech.playbackRate = 1.15; // Play 15% faster
                        currentSpeech.onended = () => {
                            currentSpeech = null;
                            resolve();
                        };
                        currentSpeech.onerror = (err) => {
                             currentSpeech = null;
                             reject(err);
                        }
                        currentSpeech.play();
                    } else {
                        throw new Error("Audio data not found in API response.");
                    }
                })
                .catch(error => {
                    console.error("Error generating or playing TTS audio:", error);
                    statusMessage.textContent = "Sorry, I couldn't generate a voice response.";
                    reject(error);
                });
            });
        }

        async function getAIAssistance(prompt, isTodoList) {
            aiLoading.classList.remove('hidden');
            recordButton.disabled = true;

            const systemPrompt = "You are Jennifer, a professional and efficient AI co-pilot. Your primary role is to listen, take notes, and ask clarifying questions to help the user organize their thoughts. Keep your conversational style concise and to the point. However, if the user's phrasing presents a very obvious opportunity for a pun, you may make one in a clever but still professional manner. Otherwise, avoid humor. IMPORTANT: When asked to generate a to-do list, your text response MUST contain ONLY the list items in markdown format (e.g., - Mow the lawn). Do NOT include any other conversational text in the written to-do list response.";
            
            let contentForAPI = [...conversationHistory];
            contentForAPI.push({ role: "user", parts: [{ text: prompt }] });
            
            const apiKey = ""; 
            const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent?key=${apiKey}`;

            const payload = {
                contents: contentForAPI,
                systemInstruction: { parts: [{ text: systemPrompt }] },
            };
            
            try {
                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                if (!response.ok) throw new Error(`API call failed with status: ${response.status}`);

                const result = await response.json();
                const candidate = result.candidates?.[0];

                if (candidate && candidate.content?.parts?.[0]?.text) {
                    const text = candidate.content.parts[0].text;
                    if (isTodoList) {
                        if (todoListDiv.querySelector('.text-gray-400')) {
                             todoListDiv.innerHTML = '';
                        }
                        const htmlList = markdownListToHtml(text);
                        todoListDiv.innerHTML = htmlList; 
                        copyToDoListButton.classList.remove('hidden');
                        // The AI's written response `text` is ONLY the list. We speak a separate confirmation.
                        await getAndPlayTTS("Got it. I've updated your to-do list for you.");
                    } else {
                        if (aiNotesDiv.querySelector('.text-gray-400')) {
                             aiNotesDiv.innerHTML = '';
                        }
                        aiNotesDiv.innerHTML = `<p><span class="font-semibold text-purple-600">Jennifer:</span> ${text}</p>`;
                         conversationHistory.push({ role: "model", parts: [{ text: text }] });
                         await getAndPlayTTS(text);
                    }
                } else {
                    throw new Error("Invalid response structure from API.");
                }
            } catch (error) {
                console.error("Error with AI Assistance:", error);
                statusMessage.textContent = "Sorry, I'm having trouble responding.";
                // In case of error, ensure we can start listening again if the session is active
                if (sessionActive) {
                    try { recognition.start(); } catch(e) {}
                }
            } finally {
                aiLoading.classList.add('hidden');
                recordButton.disabled = false;
                // Important: Only restart listening if the session is still active
                if (sessionActive) {
                    try { recognition.start(); } catch(e) {
                         console.error("Could not restart recognition in finally block:", e);
                    }
                }
            }
        }
    </script>
</body>
</html>

