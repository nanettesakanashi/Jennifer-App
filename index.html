<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Voice Assistant</title>
    
    <!-- PWA Meta Tags -->
    <meta name="theme-color" content="#DDA7A2"/>
    <link rel="manifest" href="manifest.json">
    <link rel="apple-touch-icon" href="https://placehold.co/192x192/DDA7A2/ffffff?text=AI">

    <script src="https://cdn-tailwindcss.vercel.app/"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        /* West Coast Modern Aesthetic */
        body {
            font-family: 'Inter', sans-serif;
            background-color: #F8F5F2; /* Warm, off-white background */
        }
        .assistant-card {
            background-color: #FFFFFF;
            border-radius: 0.75rem;
            border: 1px solid #EAEAEA;
            box-shadow: 0 8px 24px rgba(0, 0, 0, 0.04); /* Softer, more subtle shadow */
            transition: all 0.3s ease-in-out;
        }
        .assistant-card:hover {
            box-shadow: 0 12px 32px rgba(0, 0, 0, 0.06);
        }
        h1, h2 {
            color: #2D2D2D; /* Softer black for headings */
        }
        p, .text-gray-600 {
            color: #555555; /* Dark grey for body text */
        }
        .btn-primary {
            background-color: #DDA7A2; /* Dusty Pink */
            color: white;
            font-weight: 600;
            padding: 0.75rem 1.5rem;
            border-radius: 0.5rem;
            border: none;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .btn-primary:hover {
            background-color: #C9948F; /* Darker Dusty Pink */
        }
         .btn-primary:disabled {
            background-color: #E8C3BF; /* Lighter, muted pink */
            cursor: not-allowed;
        }
        .loader {
            border: 4px solid #f3f3f3;
            border-top: 4px solid #DDA7A2; /* Dusty Pink spinner */
            border-radius: 50%;
            width: 24px;
            height: 24px;
            animation: spin 1s linear infinite;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        .dot-flashing {
            position: relative;
            width: 10px;
            height: 10px;
            border-radius: 5px;
            background-color: #DDA7A2;
            color: #DDA7A2;
            animation: dotFlashing 1s infinite linear alternate;
            animation-delay: .5s;
            display: inline-block;
            margin: 0 4px;
        }
        .dot-flashing::before, .dot-flashing::after {
            content: '';
            display: inline-block;
            position: absolute;
            top: 0;
            width: 10px;
            height: 10px;
            border-radius: 5px;
            background-color: #DDA7A2;
            color: #DDA7A2;
            animation: dotFlashing 1s infinite alternate;
        }
        .dot-flashing::before {
            left: -15px;
            animation-delay: 0s;
        }
        .dot-flashing::after {
            left: 15px;
            animation-delay: 1s;
        }
        @keyframes dotFlashing {
            0% { background-color: #DDA7A2; }
            50%, 100% { background-color: #E8C3BF; }
        }
        .form-container {
            border-color: #ECECEC;
            background-color: #FAFAFA;
        }
        .h2-border {
             border-color: #ECECEC;
        }
    </style>
</head>
<body class="flex items-center justify-center min-h-screen p-4">

    <div class="assistant-card w-full max-w-2xl p-6 md:p-8 space-y-6">
        <div>
            <h1 class="text-3xl font-bold text-center">Jennifer, Your AI Co-Pilot</h1>
            <p class="text-center mt-2">Start talking to Jennifer. She's ready to listen.</p>
        </div>

        <div class="flex flex-col items-center space-y-4">
            <div id="statusMessage" class="text-center text-red-500 font-medium h-5"></div>
            <button id="recordButton" class="btn-primary flex items-center justify-center w-full md:w-auto">
                <svg id="mic-icon" xmlns="http://www.w3.org/2000/svg" class="h-6 w-6 mr-2" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
                  <path stroke-linecap="round" stroke-linejoin="round" d="M19 11a7 7 0 11-14 0m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z" />
                </svg>
                <span id="recordButtonText">Start Conversation</span>
            </button>
            <div id="recording-status" class="text-sm hidden items-center justify-center">
                <div class="dot-flashing"></div>
                <span id="recording-status-text" class="ml-2">Listening...</span>
            </div>
        </div>

        <!-- Conversation Log -->
        <div id="conversation-container" class="space-y-4">
             <h2 class="text-xl font-semibold border-b pb-2 h2-border">Conversation</h2>
             <div id="conversation" class="h-48 overflow-y-auto p-4 rounded-lg border form-container">
                <p class="text-gray-400">Your conversation will appear here...</p>
            </div>
        </div>

        <!-- AI Assistant Notes -->
         <div id="ai-notes-container" class="space-y-4">
             <h2 class="text-xl font-semibold border-b pb-2 h2-border">Jennifer's Follow-up</h2>
             <div id="aiNotes" class="h-32 overflow-y-auto p-4 rounded-lg border form-container">
                 <p class="text-gray-400">Jennifer's questions will appear here...</p>
             </div>
        </div>


        <!-- To-Do List -->
        <div id="todo-container" class="space-y-4">
            <h2 class="text-xl font-semibold border-b pb-2 h2-border">To-Do List</h2>
            <div id="todoList" class="p-4 rounded-lg border form-container">
                <p class="text-gray-400">Your to-do list will appear here after the conversation.</p>
            </div>
            <div class="text-center">
                <button id="copyToDoListButton" class="hidden btn-primary mt-2">Copy To-Do List</button>
                <p id="copyStatus" class="text-sm text-green-600 mt-2 h-4"></p>
            </div>
        </div>

    </div>

    <script>
        // --- CONFIG ---
        const apiKey = "AIzaSyA8mG1Xdcod9kg7lgUTHfT84_XogkmPZfQ";
        const INTERRUPT_COMMAND = "wait";

        // --- DOM ELEMENTS ---
        const UIElements = {
            recordButton: document.getElementById('recordButton'),
            recordButtonText: document.getElementById('recordButtonText'),
            statusMessage: document.getElementById('statusMessage'),
            recordingStatus: document.getElementById('recording-status'),
            recordingStatusText: document.getElementById('recording-status-text'),
            conversationDiv: document.getElementById('conversation'),
            aiNotesDiv: document.getElementById('aiNotes'),
            todoListDiv: document.getElementById('todoList'),
            copyToDoListButton: document.getElementById('copyToDoListButton'),
            copyStatus: document.getElementById('copyStatus'),
        };

        // --- STATE MANAGEMENT ---
        let state = 'IDLE'; // IDLE, LISTENING, PROCESSING, SPEAKING
        let conversationHistory = [];
        let currentSpeech = null;
        let audioCtx;
        let recognition;
        
        // --- STATE MACHINE & UI UPDATES ---
        function setState(newState) {
            if (state === newState) return;
            state = newState;
            console.log(`State changed to: ${state}`);
            updateUIForState();
        }

        function updateUIForState() {
            const isIdle = state === 'IDLE';
            const isListening = state === 'LISTENING';
            const isProcessing = state === 'PROCESSING';
            const isSpeaking = state === 'SPEAKING';

            UIElements.recordButtonText.textContent = isIdle ? 'Start Conversation' : 'End Conversation';
            UIElements.recordButton.disabled = isProcessing;

            if (isListening || isProcessing || isSpeaking) {
                UIElements.recordingStatus.classList.remove('hidden');
                UIElements.recordingStatus.classList.add('flex');
            } else {
                UIElements.recordingStatus.classList.add('hidden');
            }

            if (isListening) UIElements.recordingStatusText.textContent = 'Listening...';
            if (isProcessing) UIElements.recordingStatusText.textContent = 'Thinking...';
            if (isSpeaking) UIElements.recordingStatusText.textContent = 'Jennifer is speaking...';
        }

        // --- SPEECH RECOGNITION SETUP ---
        function initializeSpeechRecognition() {
            if (!('webkitSpeechRecognition' in window)) {
                UIElements.recordButton.disabled = true;
                UIElements.recordButtonText.textContent = 'Not Supported';
                UIElements.statusMessage.textContent = 'Speech recognition is not supported in this browser.';
                return;
            }

            recognition = new webkitSpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = 'en-US';

            recognition.onresult = handleRecognitionResult;
            recognition.onend = () => {
                if (state !== 'IDLE' && state !== 'PROCESSING') {
                   startListening();
                }
            };
            recognition.onerror = (event) => {
                if (event.error !== 'no-speech') console.error("Speech recognition error:", event.error);
            };
        }

        function handleRecognitionResult(event) {
            let interim_transcript = '';
            let final_transcript = '';

            for (let i = event.resultIndex; i < event.results.length; ++i) {
                if (event.results[i].isFinal) final_transcript += event.results[i][0].transcript;
                else interim_transcript += event.results[i][0].transcript;
            }

            if (state === 'SPEAKING' && interim_transcript.toLowerCase().includes(INTERRUPT_COMMAND)) {
                if (currentSpeech) currentSpeech.pause();
                recognition.stop();
                return;
            }
            
            if (state === 'LISTENING' && final_transcript.trim()) {
                recognition.stop();
                processUserSpeech(final_transcript.trim());
            }
        }
        
        // --- CORE LOGIC ---
        function startListening() {
            if (state !== 'LISTENING') {
                 setState('LISTENING');
                 try { recognition.start(); } catch (e) {}
            }
        }

        async function processUserSpeech(text) {
            setState('PROCESSING');
            addToConversationLog('You', text);
            conversationHistory.push({ role: "user", parts: [{ text }] });
            const aiResponse = await getAIAssistance("Respond conversationally, continuing the thread. Keep it brief.", false);
            if (aiResponse) {
                addToConversationLog('Jennifer', aiResponse.text, true);
                conversationHistory.push({ role: "model", parts: [{ text: aiResponse.text }] });
                await speak(aiResponse.audioData);
                startListening(); // Re-start listening after Jennifer is done
            } else {
                startListening(); // Also re-start listening if AI fails
            }
        }
        
        async function endConversation() {
            setState('IDLE');
            if (currentSpeech) currentSpeech.pause();
            recognition.stop();
            
            if (conversationHistory.length > 0) {
                setState('PROCESSING');
                const todoResponse = await getAIAssistance("From our entire conversation, extract only the specific tasks and action items that I have mentioned. Compile these into a concise to-do list.", true);
                if (todoResponse) {
                    UIElements.todoListDiv.innerHTML = markdownListToHtml(todoResponse.text);
                    UIElements.copyToDoListButton.classList.remove('hidden');
                    await speak(todoResponse.audioData);
                }
                setState('IDLE');
            }
            conversationHistory = [];
        }

        // --- EVENT LISTENERS ---
        UIElements.recordButton.addEventListener('click', async () => {
            if (state === 'IDLE') {
                const permissionGranted = await checkPermissionsAndInitAudio();
                if (permissionGranted) {
                    if (conversationHistory.length === 0) resetUI();
                    startListening();
                }
            } else {
                endConversation();
            }
        });

        // --- HELPERS & API CALLS ---
        async function speak(audioData) {
            if (!audioData) return Promise.resolve();
            
            return new Promise((resolve) => {
                setState('SPEAKING');
                const wavBlob = pcmToWav(new Int16Array(base64ToArrayBuffer(audioData.data)), audioData.sampleRate);
                currentSpeech = new Audio(URL.createObjectURL(wavBlob));
                currentSpeech.onended = () => {
                    currentSpeech = null;
                    resolve();
                };
                currentSpeech.onerror = (e) => {
                    currentSpeech = null;
                    console.error("Audio playback error:", e);
                    resolve(); 
                }
                currentSpeech.play();
            });
        }

        async function getAIAssistance(prompt, isTodoList) {
            const systemPrompt = "You are Jennifer, a professional and efficient AI co-pilot. Your primary role is to help the user capture and organize their thoughts by asking concise, clarifying questions. Your goal is to extract actionable tasks from the user's speech. Avoid overly agreeable phrases. If the user's phrasing presents an obvious opportunity for a pun, you may make one in a clever but still professional manner. IMPORTANT: When asked to generate a to-do list, your text response MUST contain ONLY the actionable to-do items explicitly mentioned by the user, formatted as a markdown list (e.g., - Mow the lawn). Do not add items that weren't mentioned. Do NOT include any other conversational text in the written to-do list response.";
            let contentForAPI = [...conversationHistory];
            contentForAPI.push({ role: "user", parts: [{ text: prompt }] });
            
            try {
                // Text generation
                const textApiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent?key=${apiKey}`;
                const textResponse = await fetch(textApiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ contents: contentForAPI, systemInstruction: { parts: [{ text: systemPrompt }] } })
                });
                if (!textResponse.ok) throw new Error(`Text API failed: ${textResponse.status}`);
                const textResult = await textResponse.json();
                const generatedText = textResult.candidates?.[0]?.content?.parts?.[0]?.text;
                if (!generatedText) throw new Error("No text generated.");

                // TTS generation
                const ttsText = isTodoList ? "Got it. I've updated your to-do list for you." : generatedText;
                const ttsApiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key=${apiKey}`;
                
                const ttsPayload = {
                    contents: [{ parts: [{ text: ttsText }] }],
                    generationConfig: {
                        responseModalities: ["AUDIO"],
                        speechConfig: { voiceConfig: { prebuiltVoiceConfig: { voiceName: "Erinome" } } }
                    },
                    model: "gemini-2.5-flash-preview-tts"
                };
                const ttsResponse = await fetch(ttsApiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(ttsPayload)
                });
                if (!ttsResponse.ok) {
                     const errorBody = await ttsResponse.text();
                     throw new Error(`TTS API failed: ${ttsResponse.status}. Body: ${errorBody}`);
                }
                const ttsResult = await ttsResponse.json();
                const audioContent = ttsResult.candidates?.[0]?.content?.parts?.[0]?.inlineData;
                if (!audioContent) throw new Error("No audio data in TTS response.");
                
                const sampleRate = parseInt(audioContent.mimeType.match(/rate=(\d+)/)[1], 10);
                
                return { text: generatedText, audioData: { data: audioContent.data, sampleRate: sampleRate } };

            } catch (error) {
                console.error("Error in getAIAssistance:", error.message);
                if (error.message.includes("429")) {
                    UIElements.statusMessage.textContent = "Free daily usage limit reached. Please try again tomorrow.";
                } else {
                    UIElements.statusMessage.textContent = "Sorry, I'm having trouble responding.";
                }
                setTimeout(() => UIElements.statusMessage.textContent = '', 5000);
                return null;
            }
        }

        async function checkPermissionsAndInitAudio() {
            if (apiKey === "PASTE_YOUR_KEY_HERE" || !apiKey) {
                UIElements.statusMessage.textContent = "API Key is missing in index.html";
                return false;
            }
            try {
                const permissionStatus = await navigator.permissions.query({ name: 'microphone' });
                if (permissionStatus.state === 'denied') {
                    UIElements.statusMessage.textContent = 'Microphone access is blocked. Please enable it in browser settings.';
                    return false;
                }
                if (!audioCtx) {
                    audioCtx = new (window.AudioContext || window.webkitAudioContext)();
                    const buffer = audioCtx.createBuffer(1, 1, 22050);
                    const source = audioCtx.createBufferSource();
                    source.buffer = buffer;
                    source.connect(audioCtx.destination);
                    source.start(0);
                }
                if (audioCtx.state === 'suspended') audioCtx.resume();
                return true;
            } catch (error) {
                console.error("Permissions check failed:", error);
                return true;
            }
        }
        
        function resetUI() {
            UIElements.conversationDiv.innerHTML = '<p class="text-gray-400">Your conversation will appear here...</p>';
            UIElements.aiNotesDiv.innerHTML = `<p class="text-gray-400">Jennifer's questions will appear here...</p>`;
            UIElements.todoListDiv.innerHTML = '<p class="text-gray-400">Your to-do list will appear here.</p>';
            UIElements.copyToDoListButton.classList.add('hidden');
            UIElements.copyStatus.textContent = '';
        }
        
        function addToConversationLog(speaker, text, isAI = false) {
             const div = isAI ? UIElements.aiNotesDiv : UIElements.conversationDiv;
             if (div.querySelector('.text-gray-400')) div.innerHTML = '';
             const p = document.createElement('p');
             const color = isAI ? 'text-purple-600' : 'text-indigo-600';
             p.innerHTML = `<span class="font-semibold ${color}">${speaker}:</span> ${text}`;
             div.appendChild(p);
             div.scrollTop = div.scrollHeight;
        }

        // --- UTILITIES ---
        function markdownListToHtml(text) {
            if (text.includes('<li>')) return text;
            const lines = text.trim().split('\n');
            let html = '<ul class="list-disc list-inside space-y-1 text-gray-700">';
            lines.forEach(line => {
                const trimmedLine = line.trim();
                const match = trimmedLine.match(/^[\*\-]\s+(.*)/);
                if (match) html += `<li>${match[1]}</li>`;
                else if (trimmedLine) html += `<li>${trimmedLine}</li>`;
            });
            return html + '</ul>';
        }

        function base64ToArrayBuffer(base64) {
            const binaryString = window.atob(base64);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) bytes[i] = binaryString.charCodeAt(i);
            return bytes.buffer;
        }

        function pcmToWav(pcmData, sampleRate) {
            const numChannels = 1, bitsPerSample = 16;
            const byteRate = sampleRate * numChannels * bitsPerSample / 8;
            const blockAlign = numChannels * bitsPerSample / 8;
            const dataSize = pcmData.length * 2;
            const buffer = new ArrayBuffer(44 + dataSize);
            const view = new DataView(buffer);
            view.setUint32(0, 0x52494646, false); // "RIFF"
            view.setUint32(4, 36 + dataSize, true);
            view.setUint32(8, 0x57415645, false); // "WAVE"
            view.setUint32(12, 0x666d7420, false); // "fmt "
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, numChannels, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, byteRate, true);
            view.setUint16(32, blockAlign, true);
            view.setUint16(34, bitsPerSample, true);
            view.setUint32(36, 0x64617461, false); // "data"
            view.setUint32(40, dataSize, true);
            for (let i = 0; i < pcmData.length; i++) view.setInt16(44 + i * 2, pcmData[i], true);
            return new Blob([view], { type: 'audio/wav' });
        }
        
        copyToDoListButton.addEventListener('click', () => {
            const todoItems = Array.from(UIElements.todoListDiv.querySelectorAll('li'));
            if (todoItems.length === 0) {
                UIElements.copyStatus.textContent = 'Nothing to copy.';
                setTimeout(() => { UIElements.copyStatus.textContent = '' }, 3000);
                return;
            }
            const textToCopy = todoItems.map(item => `• ${item.textContent}`).join('\n');
            const textArea = document.createElement('textarea');
            textArea.value = textToCopy;
            document.body.appendChild(textArea);
            textArea.select();
            try {
                document.execCommand('copy');
                UIElements.copyStatus.textContent = '✅ Copied to clipboard!';
            } catch (err) {
                UIElements.copyStatus.textContent = '❌ Failed to copy.';
                console.error('Failed to copy text: ', err);
            }
            document.body.removeChild(textArea);
            setTimeout(() => { UIElements.copyStatus.textContent = '' }, 3000);
        });

        // --- INITIALIZATION ---
        initializeSpeechRecognition();
        setState('IDLE');

    </script>
</body>
</html>

